# GPU Hint Generation Benchmark (Forge-Optimized Kernel)

**Date:** 2026-01-25
**Author:** Benchmarked on Modal Labs infrastructure

## Summary

Benchmark of the Forge-optimized GPU-accelerated hint generation for RMS24 PIR. The kernel was generated by Forge (rightnowai.co/forge) from a PyTorch reference implementation and uses 256 threads per hint with two-level XOR reduction.

**Key Results (Production Run λ=128, 2026-01-25):**
- **50× H200:** 10,966,016 hints in **5.4 minutes** (wall clock)
- **Total Throughput:** **49.2M hints/sec** (Aggregate)
- **Per-GPU Throughput:** **985K hints/sec** (avg)
- **Kernel Time:** **222.7 ms** median per batch of 219K hints
- **Correctness:** Verified against PyTorch reference

## Production Run Details

**Run ID:** `forge_fulldb_20260125_191208`

```text
======================================================================
RESULTS - 50× H200 Production Hint Generation (Forge Kernel, λ=128)
======================================================================
Run ID:              forge_fulldb_20260125_191208

Database Parameters:
  n (entries):       1,834,095,877 (Active entries, V3 Schema)
  Entry size:        40 bytes (5 × int64)
  Database size:     73.4 GB (Disk/VRAM)

RMS24 Parameters:
  Block size:        42,826 (sqrt of entries)
  Subset size:       21,413 per hint (half of blocks)
  Lambda (λ):        128
  Kernel:            Forge-optimized (256 threads, 8 warps)
  Reduction:         Two-level (warp shuffle + shared memory)

Hint Parameters:
  Total hints:       10,966,016 (2 × λ × block_size)
  Hints per GPU:     219,320
  Parity size:       40 bytes

Timing:
  Wall clock time:   5.4 min (323.5s)
  Avg kernel time:   222.7 ms (per 219K hints)
  DB load time:      66-113 sec (per GPU)
  Kernel compile:    ~43 sec (per GPU)

Per-Worker Stats:
  Workers:           50 × H200
  GPU Memory:        150.1 GB each
  Hints per worker:  219,320
  Subset data:       37.6 GB (per GPU)

Throughput:
  Per-GPU (Best):    989,297 hints/sec (GPU 26)
  Per-GPU (Worst):   947,890 hints/sec (GPU 7)
  Per-GPU (Avg):     984,978 hints/sec
  Cluster Total:     49,248,887 hints/sec
======================================================================
```

## Comparison with Previous Kernels

| Metric | Original (PRF on GPU) | Warp (32 threads) | Forge (256 threads) | Improvement |
| :--- | :--- | :--- | :--- | :--- |
| **Threads per hint** | 1 | 32 | **256** | 8× |
| **Per-GPU throughput** | 98 hints/sec | 2,042 hints/sec | **768,043 hints/sec** | **7,800×** |
| **50× H200 combined** | N/A | 22,855 hints/sec | **38,402,130 hints/sec** | **1,680×** |
| **Kernel time (1K hints)** | ~10s | ~500ms | **1.30 ms** | **7,700×** |
| **Subset precomputation** | None (PRF on GPU) | CPU Phase 1 | CPU Phase 1 | - |

## Comparison with Plinko (ChaCha12)

| Metric | Plinko (ChaCha12) | RMS24 (Forge) | Notes |
| :--- | :--- | :--- | :--- |
| **Cipher** | ChaCha12 + SwapOrNot | ChaCha12 (precomputed) | RMS24 uses CPU for PRF |
| **Subset selection** | 759 SwapOrNot rounds | Median cutoff | Different algorithms |
| **Per-GPU throughput** | 2,660 hints/sec | **984,978 hints/sec** | **370× faster** |
| **50× H200 combined** | 133,000 hints/sec | **49,248,887 hints/sec** | **370× faster** |
| **Hints generated** | 33,554,432 | 10,966,016 | Full production runs |
| **Wall clock time** | 12.7 min | **5.4 min** | **2.4× faster** |

**Note:** RMS24 is faster because subset selection is precomputed on CPU. Plinko computes SwapOrNot PRP on GPU for each hint.

## Kernel Optimization Details

### 1. Forge AI Optimization
The kernel was generated by [Forge](https://rightnowai.co/forge) using 32 parallel agents to optimize a PyTorch reference implementation. Key optimizations:

- **256 threads per block** (8 warps) instead of 32
- **Strided iteration** for better thread utilization
- **Two-level reduction:** Warp shuffle first, then shared memory across warps
- **Coalesced memory access** patterns

### 2. Two-Level XOR Reduction
```
Phase 1: Each thread accumulates local parity (strided access)
Phase 2: Warp-level reduction via __shfl_xor_sync (5 log(32) = 25 ops)
Phase 3: Lane 0 of each warp writes to shared memory
Phase 4: Thread 0 reduces across warps (8 iterations)
```

### 3. Precomputed Subsets
Unlike Plinko which computes SwapOrNot on GPU, RMS24 precomputes subsets on CPU:
- Subset indices stored as flattened arrays
- GPU only does gather + XOR reduction
- Eliminates PRF overhead from hot path

## Scaling Analysis

| GPUs | Hints | Combined Throughput | Per-GPU |
|------|-------|---------------------|---------|
| 1 | 1,000 | 768K/sec | 768K/sec |
| 10 | 10,000 | 7.7M/sec | 768K/sec |
| 50 | 50,000 | 38.4M/sec | 768K/sec |

Throughput scales linearly with GPU count (no shared resources).

## GPU PRF Optimization (2026-01-25)

A follow-up optimization eliminates CPU subset generation entirely by computing ChaCha12 PRF on GPU.

**Trade-off analysis:**
| Metric | CPU Subset (Forge) | GPU PRF | Trade-off |
|--------|-------------------|---------|-----------|
| Kernel time (219K hints) | 222ms | 411ms | 1.85× slower |
| Per-GPU throughput | 985K/sec | 533K/sec | 1.85× slower |
| Combined (50 GPU) | 49.2M/sec | 26.7M/sec | 1.85× slower |
| Subset gen time | 65s | **0s** | **∞ faster** |
| Data transfer | 37.6GB/GPU | **0** | **∞ faster** |
| Wall clock | 4.6 min | **4.5 min** | **2% faster** |

**When to use GPU PRF:**
- Single-client latency critical (0.41s vs 75s per-client)
- Memory-constrained GPUs (no 37.6GB buffer needed)
- Warm GPU pool (skip subset gen on each request)

**When to use CPU Subset:**
- Maximum raw throughput needed
- Batching many clients (amortize subset gen cost)
- CPU cores available for parallel subset generation

## Artifacts

**Benchmark Results:**
- [benchmark_forge_fulldb_50gpu_20260125.json](benchmark_forge_fulldb_50gpu_20260125.json) - Full database results
- [benchmark_forge_50gpu_synthetic_20260125.json](benchmark_forge_50gpu_synthetic_20260125.json) - Synthetic benchmark

**Kernel Source:**
- [hint_kernel.cu](../cuda/hint_kernel.cu) - CUDA kernel implementations (Forge kernel)
- [subset_gen_kernel.cu](../cuda/subset_gen_kernel.cu) - GPU PRF subset generation
- [modal_forge_fulldb.py](../scripts/modal_forge_fulldb.py) - CPU subset benchmark
- [modal_forge_gpu_subset.py](../scripts/modal_forge_gpu_subset.py) - GPU PRF benchmark
